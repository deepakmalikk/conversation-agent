import json
from models import QueryResponse
from embedding import EmbeddingGenerator
from faiss_manager import FAISSManager
from pydantic_ai import Agent
import os
from dotenv import load_dotenv

load_dotenv()

gemini_api_key = os.getenv('GEMINI_API_KEY')

class QueryAgent:
    def __init__(self, dimension: int = 384, threshold: float = 0.5, history_file: str = "history.json"):
        self.embedding_generator = EmbeddingGenerator()
        self.faiss_manager = FAISSManager(dimension)
        self.threshold = threshold
        self.history_file = history_file
        
        # Load previous conversation history if exists
        self.context = self.load_conversation_history()

    def load_conversation_history(self) -> list:
        """Load the conversation history from a file (if it exists)."""
        if os.path.exists(self.history_file):
            with open(self.history_file, 'r') as f:
                return json.load(f)
        return []  # Return an empty list if no history exists

    def save_conversation_history(self):
        """Save the conversation history to a file."""
        with open(self.history_file, 'w') as f:
            json.dump(self.context, f, indent=4)

    def handle_query(self, query: str) -> str:
        # Generate embedding for the new query
        embedding = self.embedding_generator.generate_embedding(query)

        # Find related queries from FAISS
        related_queries = self.faiss_manager.get_related_queries(embedding, self.threshold)
        related_texts = " ".join([r.query for r in related_queries])

        # Combine query and related queries to form the combined query
        combined_query = f"{query} {related_texts}"

        # Generate response (with full context)
        response = self.generate_response(combined_query)

        # Store the new query-response pair in context
        self.context.append({"query": query, "response": response})

        # Save the updated conversation history
        self.save_conversation_history()

        # Store the new query-response pair in FAISS for future retrieval
        query_response = QueryResponse(query=query, response=response, embedding=embedding.tolist())
        self.faiss_manager.add_record(query_response)

        return response

    def generate_response(self, combined_query: str) -> str:
        # Build the full context: previous queries and responses
        full_context = "\n".join([f"Q: {entry['query']}\nA: {entry['response']}" for entry in self.context])
        full_context += f"\nQ: {combined_query}"

        # Initialize the agent without the context parameter
        agent = Agent(
            model='gemini-1.5-flash',
            system_prompt='You are a helpful assistant that remembers all past interactions. Previous context:\n' + full_context
        )

        # Get the result from Gemini
        result = agent.run_sync(combined_query)
        print(result.data)  # You can check the raw response for debugging
        return result.data  # Return the response generated by Gemini